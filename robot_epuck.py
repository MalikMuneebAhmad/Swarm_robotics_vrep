import sim as vrep  # V-rep library
import sys
import time  # used to keep track of time
import numpy as np  # array library
import math
import random
import datetime
import psutil
from utlis import *


def extract_name(sensor_name):
    size = len(sensor_name)
    specify = size - sensor_name.find('#')
    robot_number = sensor_name[-specify:]
    sensor_ch = sensor_name[:size - specify]
    return sensor_ch, robot_number


class Robot:
    p = 1 / 8

    def __init__(self, clientID, robot_name, sensor_name):
        self.clientID = clientID
        self.robot_name = robot_name
        self.sensor_name = sensor_name
        self.sensor_ch, self.robot_number = extract_name(self.sensor_name)
        self.num_sensors = int(8)  # Numbers of sensor attached to robot
        self.sensor_handles = np.array([], dtype='i')  # Handles of Sensors
        self.Vision_sensor_handles = np.array([], dtype='i')  # Handles of Sensors
        self.vision_sensor_values = np.zeros([self.num_sensors])
        self.front_Vision_sensor = int()
        self.sensors_detecting = np.ones(self.num_sensors,
                                         dtype='i') * -1  # Presence of robot, obstacle and no presence
        self.detectionStates = [False] * self.num_sensors  # States of Sensors detecting or not
        self.robot_position = list()
        self.sensors_position = np.zeros([self.num_sensors, 3])  # Position of Sensors w.r.t robot frame of reference
        self.sensor_values = np.array([0.000] * self.num_sensors)  # Sensors values Modified
        self.sensor_avoid = np.array([0.000] * self.num_sensors)  # Redundant right now
        self.sensor_raw_values = np.array([0.000] * self.num_sensors)  # Raw Values Generated by Sensors
        self.sensor_angles = np.array([])  # Angles of sensors w.r.t Heading Direction
        self.currrent_gradient = float()  # Gradient along the heading direction
        self.det_obj_handles = [0] * self.num_sensors  # Handles acquired by all sensors of a robot
        self.static_object_handles = list()  # All objects handles who need to be avoided
        self.det_rob = list()  # Handles of robots detected by a robot
        self.det_obj = list()  # Handles of objects detected by a robot
        self.obj_avoid = False  # Condition to Regulate Object Avoidance
        ob_num = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']  # name of objects
        for i in ob_num:  # Loop to acquire Handles of all objects
            errorCode, object_handle = vrep.simxGetObjectHandle(clientID, 'Cuboid' + i, vrep.simx_opmode_blocking)
            self.static_object_handles.append(object_handle)
        self.vmax = float(5)  # Maximum angular speed of robot
        self.r_rot = False  # Condition to regulate random motion
        self.levy_var = int(0)  # To count the number of straight
        self.no_nei = int()
        self.semi_mature_flock = False  # Condition for semi mature behavior in flocking
        self.thetas = {0: 0.0, 1: 45, 2: 90, 3: 135, 4: 180, 5: -135, 6: -90,
                       7: -45}  # Dictionary to assign specific angle
        self.theta = 0.0  # Angle of rotation of robot
        self.l = 0.053  # Distance Between two wheels
        self.r = 0.0199535  # Redius of Wheels
        self.detected_object_handles = [0] * self.num_sensors
        self.front_ok = False
        self.presence_in_gradient = False

        # -------------------get the handles of Ultrasonic sensors and motors-----------------#
        # Robot Handle and its position initialization function
        self.errorCode, self.robot_handle = vrep.simxGetObjectHandle(clientID, self.robot_name,
                                                                     vrep.simx_opmode_oneshot_wait)
        self.returnCode, self.robot_position = vrep.simxGetObjectPosition(clientID, self.robot_handle, -1,
                                                                          vrep.simx_opmode_streaming)
        # Get robot position
        self.returnCode, self.robot_position = vrep.simxGetObjectPosition(clientID, self.robot_handle, -1,
                                                                          vrep.simx_opmode_buffer)
        errorCode, self.front_Vision_sensor = vrep.simxGetObjectHandle(clientID, 'Vision_sensor0' + self.robot_number,
                                                            vrep.simx_opmode_blocking)  # Retr ieving Sensor handles

        for x in range(1, self.num_sensors + 1):  # Sensor Handles Access
            # print(self.sensor_ch + str(x) + self.robot_number)
            self.errorCode, sensor_handle = vrep.simxGetObjectHandle(clientID,
                                                                     self.sensor_ch + str(x) + self.robot_number,
                                                                     vrep.simx_opmode_oneshot_wait)  # Retrieving Sensor handles
            self.sensor_handles = np.append(self.sensor_handles, sensor_handle)
            self.errorCode, detectionState, detectedPoint, detectedObjectHandle, detectedSurfaceNormalVector = vrep.simxReadProximitySensor(
                self.clientID, sensor_handle, vrep.simx_opmode_oneshot_wait)  # First call for Read ultrasonic Sensor

            self.returnCode, sensor_position = vrep.simxGetObjectPosition(clientID, self.sensor_handles[x - 1],
                                                                          -1, vrep.simx_opmode_streaming)  # Retrieving Sensor position w.r.t Robot
            self.sensors_position[x - 1] = sensor_position
        #---------------------Vision Sensor------------#
        for v in range(1, self.num_sensors + 1):  # Sensor Handles Access
            print('Vision_sensor' + str(v) + self.robot_number)
            self.errorCode, vision_sensor_handle = vrep.simxGetObjectHandle(clientID, 'Vision_sensor' + str(v) + self.robot_number,
                                                                     vrep.simx_opmode_blocking)  # Retrieving Sensor handles
            self.Vision_sensor_handles = np.append(self.Vision_sensor_handles, vision_sensor_handle)
            #print('self.Vision_sensor_handles', self.Vision_sensor_handles)
        self.sensor_angles = np.array([-90, -45, 0, 45, 90, 135, 180, -135]) * (
                math.pi / 180)  # Angles of values of sensors
        # print('sensor_angles', self.sensor_angles)
        #self.sensor_angles = np.array([-88.80256321, -50.3427192, -1.24791524, 45.4932798,
               #95.0678522, 133.79454788, 178.85683315, -133.50366118]) * (math.pi / 180)
        self.errorCode, self.left_motor_handle = vrep.simxGetObjectHandle(clientID,
                                                                          'ePuck_leftJoint' + self.robot_number,
                                                                          vrep.simx_opmode_oneshot_wait)
        # Find motors handles
        self.errorCode, self.right_motor_handle = vrep.simxGetObjectHandle(clientID,
                                                                           'ePuck_rightJoint' + self.robot_number,
                                                                           vrep.simx_opmode_oneshot_wait)

    def ultrasonic_values(self):  # Calculate distances for ultrasonic Sensors
        self.det_rob = list()
        self.det_obj = list()
        for s in range(1, self.num_sensors + 1):
            self.errorCode, detectionState, detectedPoint, detectedObjectHandle, detectedSurfaceNormalVector = vrep.simxReadProximitySensor(
                self.clientID, self.sensor_handles[s - 1],
                vrep.simx_opmode_streaming + 000)  # Measure distance using Ultrasonic Sensor
            self.detectionStates[s - 1] = detectionState  # Sensor state detecting or not
            self.detected_object_handles[s - 1] = detectedObjectHandle
            # print('detectedObjectHandle', detectedObjectHandle)
            if not detectionState:  # To overcome out of bound distance problem
                detectedPoint = [0.0] * 3
                if s == 2:
                    self.front_ok = True
                self.det_obj_handles[s - 1] = 0
                self.sensors_detecting[s - 1] = -1
            else:  # when point is connected either it is a robot or an object
                self.det_obj_handles[s - 1] = detectedObjectHandle
                if detectedObjectHandle in self.static_object_handles:  # when robot sensor detect an object
                    self.det_obj.append(detectedObjectHandle)
                    self.sensors_detecting[s - 1] = 0
                else:  # # when robot sensor detect a robot
                    self.det_rob.append(detectedObjectHandle)
                    self.sensors_detecting[s - 1] = 1
            dist = np.linalg.norm(detectedPoint)  # Calculation of distance
            self.sensor_raw_values[s - 1] = dist
        # self.sensor_values = np.round(self.sensor_values, 2)
        self.sensor_raw_values = np.round(self.sensor_raw_values, 2)
        # print('sensor raw values', self.sensor_raw_values)
        self.no_nei = len(self.det_rob)
        return self.sensor_raw_values, self.detectionStates

    def vision_sensor(self):
        returnCode, detectidonState, auxPackets = vrep.simxReadVisionSensor(self.clientID, self.Vision_sensor_handles[2],
                                                                           vrep.simx_opmode_streaming + 000)
        #print('auxPackets', auxPackets)
        if auxPackets == []:
            auxPackets = [[0.75] * 15]
        ir_sensor_raw_value = auxPackets[0][1]
        int_red = auxPackets[0][1]
        ir_sensor_value = 0 if ir_sensor_raw_value < 0.05 else 1
        pre_red = 1 if int_red > 0.95 else 0
        return ir_sensor_value, pre_red

    def front_vision_sensor(self):
        returnCode, detectidonState, auxPackets = vrep.simxReadVisionSensor(self.clientID, self.front_Vision_sensor,
                                                                           vrep.simx_opmode_streaming)
        if auxPackets == []:
            auxPackets = [[0.0] * 15]
        ir_sensor_raw_value = auxPackets[0][1]
        ir_sensor_value = 0 if ir_sensor_raw_value < 0.05 else 1
        #--------------To get greyscale image--------#
        #returnCode, resolution, image = vrep.simxGetVisionSensorImage(self.clientID, self.front_Vision_sensor, 2,
                                                                      #vrep.simx_opmode_streaming + 5)
        # ir_sensor_value = 0 if image == [0] else 1
        return ir_sensor_raw_value, ir_sensor_value

    def read_vision_sensor(self):
        for s in range(1, self.num_sensors + 1):
            self.returnCode, detectidonState, auxPackets = vrep.simxReadVisionSensor(self.clientID, self.Vision_sensor_handles[s-1],
                                                                                vrep.simx_opmode_streaming)
            #print('vision_snsor return code', self.returnCode)
            #print('detectidonState', detectidonState)
            #print('auxPackets', auxPackets)
            auxPackets = [[0] * 15] if auxPackets == [] else auxPackets
            self.vision_sensor_values[s-1] = auxPackets[0][1]
        #print(' All Vision values', self.vision_sensor_values)
        return self.vision_sensor_values

    def send_signal(self):
        self.returnCode = vrep.simxSetIntegerSignal(self.clientID, 'Presence', self.ir_sensor_value, vrep.simx_opmode_oneshot)

    def receive_signal(self):
        self.returnCode = vrep.simxSetIntegerSignal(self.clientID, 'Presence', vrep.simx_opmode_oneshot)

    def sensor_mod_values(self, mindist, maxdist):  # Minimum and maximum distances b/w Robots
        self.sensor_values = np.array([0.0] * self.num_sensors)  # and Objects
        for i in range(self.num_sensors):
            if mindist > self.sensor_raw_values[i] > 0.02:
                # print('Distace', dist)
                self.sensor_values[i] = self.sensor_raw_values[i] - mindist
                #self.sensor_avoid[i] = self.sensor_raw_values[i] - mindist
            elif self.sensor_raw_values[i] > maxdist:
                self.sensor_values[i] = self.sensor_raw_values[i] - maxdist
                #self.sensor_avoid[i] = self.sensor_raw_values[i]
            elif self.sensor_raw_values[i]:
                self.sensor_values[i] = 0.0
                #self.sensor_avoid[i] = 0.3
        # print('Sensor values', self.sensor_values)
        return self.sensor_values

    def sensor_avoidance_values(self, mlimt_dist, sensor_range):  # Minimum and maximum distances b/w Robots
        self.sensor_avoid = np.array([0.0] * self.num_sensors)  # and Objects
        for i in range(self.num_sensors):
            if mlimt_dist > self.sensor_raw_values[i] > 0.02:
                self.sensor_avoid[i] = self.sensor_raw_values[i] - mlimt_dist
            elif self.sensor_raw_values[i] > mlimt_dist:
                self.sensor_avoid[i] = self.sensor_raw_values[i] - sensor_range
            elif self.sensor_raw_values[i]:
                self.sensor_avoid[i] = 0.0
        # print('Sensor avoid values', self.sensor_avoid)
        return self.sensor_avoid

    def object_avoidance(self, avoidable_obj, front_maxdist):  # Avoid the object in front of robot
        theta = 0.0
        self.obj_avoid = False
        obj_avoid_cond = (self.detectionStates[2] and (self.det_obj_handles[
                                                           2] in avoidable_obj)) # or (self.detectionStates[6] and (self.det_obj_handles[6] in self.static_object_handles))
        # Avoid the objects along the directional Axis
        if obj_avoid_cond and (front_maxdist >= self.sensor_raw_values[
            2] > 0.01):  # or (front_maxdist >= self.sensor_raw_values[6] > 0.01)):
            self.obj_avoid = True
            print('Object avoidance behavior is active')
            #print(' Sensor values in ob_AAVOI', self.sensor_avoid)
            fx = self.sensor_avoid * np.cos(self.sensor_angles)
            fy = self.sensor_avoid * np.sin(self.sensor_angles)
            #print('fx = ', fx)
            #print('fy = ', fy)
            fres_x = np.sum(fx)
            fres_y = np.sum(fy)
            avoid_angle = - math.atan2(fres_y, fres_x)
            if abs(avoid_angle) < math.pi/6:
                theta = math.pi/4 if avoid_angle >= 0 else -math.pi/4
            else:
                theta = avoid_angle
            #print('avoid_angle', avoid_angle)
        #elif self.det_obj != []:  # random straight movement after object avoidance
            #print('Required a random straight movement')
            #self.r_rot = not self.r_rot  # May be False
            #self.obj_avoid = True
        return theta

    def vision_sensor_gradient(self, vision_sensor_values):
        theta = 0.0
        max_grad = 0.0
        # P = [pE, pEN, pN, pNW, pW, pWS, pS, pSE]
        if not self.obj_avoid:
            gradx = vision_sensor_values[2] - vision_sensor_values[6]
            grady = vision_sensor_values[0] - vision_sensor_values[4]
            gradxy = vision_sensor_values[1] - vision_sensor_values[5]
            gradyx = vision_sensor_values[7] - vision_sensor_values[3]
            all_grad = np.array([gradx, grady, gradxy, gradyx])
            max_grad = np.max(abs(all_grad))
            if max_grad == 0.0:  # To overcome infinite array
                all_grad = np.array([0.0] * 4)
            else:  # maximum gradient is calculated
                all_grad = all_grad / (max_grad * 8)
            #print('vision sensor gradient', all_grad)
            p_array = [Robot.p + all_grad[0], Robot.p + all_grad[2], Robot.p + all_grad[1], Robot.p + all_grad[3],
                 Robot.p - all_grad[0], Robot.p - all_grad[2], Robot.p - all_grad[1],
                 Robot.p - all_grad[3]]  # Change probability w.r.t Gradient
            '''simulation = [random.randrange(8) * 1 for _ in range(16)]  # Randomly choose between 0-7 for 16 times
            freq = [simulation.count(i) for i in range(8)]  # Count the occuring of each number(event)
            directions = np.array([float(i * j) for i, j in zip(p_array, freq)])'''  # Possibility of each direction
            suitable_theta = np.argmax(p_array)  # Select the maximum likelihood direction
            theta = self.thetas[suitable_theta] * math.pi / 180
        return max_grad, theta

    def flock_com(self, target_value, target_theta, weight_forces, weight_target):  # Input is target point location (in terms of vector)
        # self.sensors_detecting will be utuilized to remove effect of obstacles from sensor values
        rob_effect = self.sensors_detecting[:5] * self.sensor_values[:5]
        f_res_x, f_res_y = resultant_vector(rob_effect, self.sensor_angles[:5])
        target_x, target_y = resultant_vector(target_value, target_theta)
        self.no_nei = 1 if self.no_nei == 0 else self.no_nei
        com_x = (weight_forces * f_res_x / self.no_nei) + (weight_target * target_x)
        com_y = (weight_forces * f_res_y / self.no_nei) + (weight_target * target_y)
        return com_x, com_y

    def straight_gradient_movement(self):
        v_l = 0
        v_r = 0
        rot_time = 0
        front_value = self.sensor_values[2]
        rare_value = self.sensor_values[6]
        print('self.detectionStates', self.detectionStates[2])
        if not self.front_ok:
            front_value = 0.3
        currrent_gradient = front_value - rare_value
        if currrent_gradient > 0.0 and (
        not self.det_obj_handles[2] in self.static_object_handles):  # Move straight
            gradient = 0.07 if currrent_gradient < 0.07 else self.currrent_gradient
            v_l = gradient * 50
            v_r = gradient * 50
            rot_time = 2
            print('Robot Movement with {} and {} in the case of +ve current gradient '.format(v_r, v_l))
            # print('Robot will move straight with time {} and velocities {} and {}'.format(rot_time, v_r, v_l))
        elif currrent_gradient < 0.0 and (
        not self.det_obj_handles[6] in self.static_object_handles):  # Move backword
            gradient = - 0.07 if self.currrent_gradient > -0.07 else self.currrent_gradient
            v_l = currrent_gradient * 10
            v_r = currrent_gradient * 10
            rot_time = 2
            print('Robot Movement with {} and {} in the case of -ve current gradient '.format(v_r, v_l))
            # print('Robot will move backword with time {} and velocities {} and {}'.format(rot_time, v_r, v_l))
        elif currrent_gradient == 0.0 and self.det_rob:  # condition to stop the robot at specific distace
            v_l = 4
            v_r = 4
            rot_time = 2
        return v_l, v_r, rot_time

    def current_com(self, comp_x, comp_y, theta, pos):  # Convert previous COM into current frame of seference
        pos_x, pos_y = resultant_vector(pos, theta)
        compc_x = (comp_x - pos_x)  # Center of mass previous now in current ref frame
        compc_y = (comp_y - pos_y)  # Center of mass previous now in current ref frame
        return compc_x, compc_y

    def chemotaxis_gradient(self):
        all_grad = np.zeros([4])
        max_grad = 0.0
        print('self.sensor_values', self.sensor_values)
        grad_sensor_values = self.sensor_values * self.sensors_detecting  # To influence only from
        print('grad_sensor_values', grad_sensor_values)
        self.currrent_gradient = grad_sensor_values[2] - grad_sensor_values[6]
        #self.currrent_gradient = self.sensor_values[2] - self.sensor_values[6]
        if (not self.detectionStates[2]) and (not self.detectionStates[6]) or self.currrent_gradient == 0: # or self.currrent_gradient == 0:  # Gradient along line of contact become Zero
            gradx = grad_sensor_values[2] - grad_sensor_values[6]
            grady = grad_sensor_values[0] - grad_sensor_values[4]
            gradxy = grad_sensor_values[1] - grad_sensor_values[5]
            gradyx = grad_sensor_values[7] - grad_sensor_values[3]
            all_grad = np.array([gradx, grady, gradxy, gradyx])
            max_grad = np.max(abs(all_grad))
            if max_grad == 0.0:  # To overcome infinite array
                all_grad = np.array([0.0] * 4)
            else:  # maximum gradient is calculated
                all_grad = all_grad / (max_grad * 8)
        return all_grad, max_grad

    def rotational_angle(self, all_grad, max_grad, theta):  # Find the angle in the direction of detected robot
        if not self.obj_avoid:  # To save conflicting angle (Object Avoidance And Chemotaxis)
            suitable_theta = 0
            # P = [pE, pEN, pN, pNW, pW, pWS, pS, pSE]
            P = [Robot.p + all_grad[0], Robot.p + all_grad[2], Robot.p + all_grad[1], Robot.p + all_grad[3],
                 Robot.p - all_grad[0], Robot.p - all_grad[2], Robot.p - all_grad[1],
                 Robot.p - all_grad[3]]  # Change probability w.r.t Gradient
            if max_grad != 0.0:  # Movement in the direction of maximum gradient
                suitable_theta = np.argmax(P)  # without randomness
                #print('Robot will move Specifically at an angle of')
            elif self.r_rot:  # For Random rotational movement of a single robot
                simulation = [random.randrange(8) * 1 for _ in range(16)]  # Randomly choose between 0-7 for 16 times
                freq = [simulation.count(i) for i in range(8)]  # Count the occuring of each number(event)
                directions = np.array([float(i * j) for i, j in zip(P, freq)])  # Possibility of each direction
                suitable_theta = np.argmax(directions)  # Select the maximum likelihood direction
                self.r_rot = False  # To get random straight movement after random rotation
                #print('Robot will move randomly at an angle of')
            theta = (self.thetas[suitable_theta] * math.pi / 180)
        return theta

    def displacement_robot(self, s):  # give s in unit of meters
        disp_time = 1.0
        v = (s * 2.372) / (self.r * disp_time)
        if v > self.vmax:
            v = self.vmax
            disp_time = (s * 2.372) / (self.r * self.vmax)
        v_l = v
        v_r = v
        return v_l, v_r, disp_time

    def rotation_robot(self, theta, reg_fac):
        #rot_time = random.uniform(1.0, 2.0)
        rot_time = 1.5
        v = abs(0.053 * theta) / (2 * rot_time * self.r) * reg_fac
        if v > self.vmax:
            v = self.vmax
            rot_time = abs(0.053 * theta) / (2 * self.vmax * self.r) * reg_fac
        v_r = -v if theta < 0 else v
        v_l = -v_r
        return v_l, v_r, rot_time

    def control_param(self, theta, r_fac):  # Convert theta to motor speed
        if theta != 0:  # For both Random and Specific Rotation
            rot_time = random.uniform(1.0, 2.0)
            v = abs(0.053 * theta) / (2 * rot_time * self.r)
            if v > self.vmax:
                v = self.vmax
                rot_time = abs(0.053 * theta) / (2 * self.vmax * self.r)
            v_r = -v if theta < 0 else v
            v_l = -v_r
            # print('Robot will rotate with time {} and velocities {} and {}'.format(rot_time, v_r, v_l))
        else:  # For straight movement or reverse movement along current axis
            if self.currrent_gradient > 0.0 and (not self.det_obj_handles[2] in self.static_object_handles):  # Move straight
                gradient = 0.07 if self.currrent_gradient < 0.07 else self.currrent_gradient
                v_l = gradient * 15
                v_r = gradient * 15
                rot_time = 2
                print('Robot Movement with {} and {} in the case of +ve current gradient '.format(v_r, v_l))
                # print('Robot will move straight with time {} and velocities {} and {}'.format(rot_time, v_r, v_l))
            elif self.currrent_gradient < 0.0 and (not self.det_obj_handles[6] in self.static_object_handles):  # Move backword
                gradient = - 0.07 if self.currrent_gradient > -0.07 else self.currrent_gradient
                v_l = self.currrent_gradient * 15
                v_r = self.currrent_gradient * 15
                rot_time = 2
                print('Robot Movement with {} and {} in the case of -ve current gradient '.format(v_r, v_l))
                # print('Robot will move backword with time {} and velocities {} and {}'.format(rot_time, v_r, v_l))
            elif self.currrent_gradient == 0.0 and self.det_rob:  #condition to stop the robot at specific distace
                v_l = 1
                v_r = 1
                rot_time = 2
                print('Robot Movement with {} and {} in zero gradient '.format(v_r, v_l))
                #v_l = self.currrent_gradient * 30
                #v_r = self.currrent_gradient * 30
                #rot_time = 1
            else:  # self.r_rot:  #  Move Randomly straight
                v_l = 2.5 * r_fac
                v_r = 2.5 * r_fac
                rot_time = random.uniform(2.0, 3.0)
                print('Straight Random Movement after random rotation')
                self.r_rot = True  # To Randomly rotate in next step
        return v_l, v_r, rot_time

    def set_position(self, pos_array):
        self.returnCode = vrep.simxSetObjectPosition(self.clientID, self.robot_handle, -1, pos_array,
                                                                          vrep.simx_opmode_oneshot)

    def get_position(self):
        self.returnCode, self.robot_position = vrep.simxGetObjectPosition(self.clientID, self.robot_handle, -1,
                                                vrep.simx_opmode_streaming)  # robot pos w.r.t world frame of reference
        self.returnCode, front_sensor_pos = vrep.simxGetObjectPosition(self.clientID, self.sensor_handles[2], -1,
                                                vrep.simx_opmode_streaming)  # front sensor pos w.r.t world frame of reference
        self.robot_position = np.array(self.robot_position)
        front_sensor_pos = np.array(front_sensor_pos)
        self.robot_position = np.ones(3) if np.all(self.robot_position == 0) else self.robot_position
        front_sensor_pos = np.zeros(3) if np.all(front_sensor_pos == 0) else front_sensor_pos
        disp, dir_rob_wax = angles_calcu(front_sensor_pos[0], front_sensor_pos[1], self.robot_position[0], self.robot_position[1])  # get pos of front sensor w.r.t world frame of ref

        return self.robot_position[0:2], disp, dir_rob_wax

    def neighbor_check(self):
        nei_status = False
        self.no_nei = self.detectionStates.count(True)
        if self.no_nei > 1:
            nei_status = True
        return nei_status

    def movement(self, v_left, v_right):
        self.errorCode = vrep.simxSetJointTargetVelocity(self.clientID, self.left_motor_handle, v_left,
                                                         vrep.simx_opmode_oneshot)

        self.errorCode = vrep.simxSetJointTargetVelocity(self.clientID, self.right_motor_handle, v_right,
                                                         vrep.simx_opmode_oneshot)

    def wait(self, t):
        self.errorCode = vrep.simxSetJointTargetVelocity(self.clientID, self.left_motor_handle, 0.0,
                                                         vrep.simx_opmode_oneshot)
        self.errorCode = vrep.simxSetJointTargetVelocity(self.clientID, self.right_motor_handle, 0.0,
                                                         vrep.simx_opmode_oneshot)
        time.sleep(t)

    def random_straight(self, fac, time_factor):  # To leave robot in a specific angle
        v_l = fac * 1.75
        v_r = fac * 2.5
        rot_time = random.uniform(2.0, 2.5) * time_factor
        return v_l, v_r, rot_time

    def random_comp_straight(self, fac, time_factor):  # random straight movement
        v_l = fac * 2.5
        v_r = fac * 2.5
        rot_time = random.uniform(2.0, 2.5) * time_factor
        return v_l, v_r, rot_time

    def levy_flight(self, fac, time_factor):  # Straight Random movement in levy flight
        v_l = fac * 2.5
        v_r = fac * 2.5
        rot_time = random.uniform(2.0, 2.5) * time_factor
        self.levy_var += 1  #  Increase every time when robot go straight
        return v_l, v_r, rot_time

    def random_rotation_angle(self):
        theta = 0.0
        if (self.levy_var % 17) >= 5 and (self.levy_var % 2) == 1:  # For Random movement of a single robot
            simulation = [random.randrange(8) * 1 for _ in range(16)]  # Randomly choose between 0-7 for 16 times
            freq = [simulation.count(i) for i in range(8)]  # Count the occuring of each number(event)
            p = [0.125] * 8
            directions = np.array([float(i * j) for i, j in zip(p, freq)])  # Possibility of each direction
            suitable_theta = np.argmax(directions)  # Select the maximum likelihood direction
            # print('Robot will move randomly at an angle of')
            theta = (self.thetas[suitable_theta] * math.pi / 180)
            self.levy_var += 1
            print('Levy theta', theta)
            #self.levy_var = 0
        return theta


'''class Robot1:
    p = 1 / 8

    def __init__(self, clientID, robot_name, sensor_name):
        self.clientID = clientID
        self.robot_name = robot_name
        self.sensor_name = sensor_name
        self.sensor_ch, self.robot_number = extract_name(self.sensor_name)
        self.num_sensors = int(8)  # Numbers of sensor attached to robot
        self.sensor_handles = np.array([], dtype='i')  # Handles of Sensors
        self.sensors_detecting = np.zeros(self.num_sensors,
                                         dtype='i') * -1  # Presence of robot, obstacle and no presence
        self.detectionStates = [False] * self.num_sensors  # States of Sensors detecting or not
        self.sensors_position = np.zeros([self.num_sensors, 3])  # Position of Sensors w.r.t robot frame of reference
        self.sensor_values = np.array([0.0] * self.num_sensors)  # Sensors values Modified
        self.sensor_avoid = np.array([0.000] * self.num_sensors)  # Redundant right now
        self.sensor_raw_values = np.array([0.000] * self.num_sensors)  # Raw Values Generated by Sensors
        self.sensor_angles = np.array([])  # Angles of sensors w.r.t Heading Direction
        self.currrent_gradient = float()  # Gradient along the heading direction
        self.det_obj_handles = [0] * self.num_sensors # Handles acquired by all sensors of a robot
        self.static_object_handles = list()  # All objects handles who need to be avoided
        self.det_rob = list()  # Handles of robots detected by a robot
        self.det_obj = list()  # Handles of objects detected by a robot
        self.obj_avoid = False  # Condition to Regulate Object Avoidance
        ob_num = ['0', '1', '2', '3', '4', '5', '6', '7']  # name of objects
        for i in ob_num:  # Loop to acquire Handles of all objects
            errorCode, object_handle = vrep.simxGetObjectHandle(clientID, 'Cuboid' + i, vrep.simx_opmode_blocking)
            self.static_object_handles.append(object_handle)
        self.vmax = float(5)  # Maximum angular speed of robot
        self.r_rot = False  # Condition to regulate random motion
        self.no_nei = int()
        self.thetas = {0: 0.0, 1: 45, 2: 90, 3: 135, 4: 180, 5: -135, 6: -90,
                       7: -45}  # Dictionary to assign specific angle
        self.theta = 0.0  # Angle of rotation of robot
        self.l = 0.053  # Distance Between two wheels
        self.r = 0.0201  # Redius of Wheels

        # -------------------get the handles of Ultrasonic sensors and motors-----------------#
        # Robot Handle and its position initialization function
        self.errorCode, self.robot_handle = vrep.simxGetObjectHandle(clientID, self.robot_name,
                                                                     vrep.simx_opmode_oneshot_wait)
        self.returnCode, self.robot_position = vrep.simxGetObjectPosition(clientID, self.robot_handle, -1,
                                                                          vrep.simx_opmode_streaming)
        # Get robot position
        self.returnCode, self.robot_position = vrep.simxGetObjectPosition(clientID, self.robot_handle, -1,
                                                                          vrep.simx_opmode_oneshot_wait)

        for x in range(1, self.num_sensors + 1):  # Sensor Handles Access
            # print(self.sensor_ch + str(x) + self.robot_number)
            self.errorCode, sensor_handle = vrep.simxGetObjectHandle(clientID,
                                                                     self.sensor_ch + str(x) + self.robot_number,
                                                                     vrep.simx_opmode_oneshot_wait)  # Retrieving Sensor handles
            self.sensor_handles = np.append(self.sensor_handles, sensor_handle)
            self.errorCode, detectionState, detectedPoint, detectedObjectHandle, detectedSurfaceNormalVector = vrep.simxReadProximitySensor(
                self.clientID, sensor_handle, vrep.simx_opmode_streaming)  # First call for Read ultrasonic Sensor

            self.returnCode, sensor_position = vrep.simxGetObjectPosition(clientID, self.sensor_handles[x - 1],
                                                                          vrep.sim_handle_parent,
                                                                          vrep.simx_opmode_oneshot_wait)  # Retrieving Sensor position w.r.t Robot
            self.sensors_position[x - 1] = sensor_position
        # print('sensors_position', self.sensors_position)
        # mag, self.sensor_angles = angles_calcu(self.sensors_position[:, 1], self.sensors_position[:, 0], 0.0, 0.0)
        #self.sensor_angles = np.array([90, 45, 0, -45, -90, -135, 180, 135]) * (
                #math.pi / 180)  # Angles of Sensors w.r.t direction axis
        self.sensor_angles = np.array([-88.80256321, -50.3427192, -1.24791524, 45.4932798,
               95.0678522, 133.79454788, 178.85683315, -133.50366118])
        # print('sensor_angles', self.sensor_angles)
        self.errorCode, self.left_motor_handle = vrep.simxGetObjectHandle(clientID,
                                                                          'ePuck_leftJoint' + self.robot_number,
                                                                          vrep.simx_opmode_oneshot_wait)
        # Find motors handles
        self.errorCode, self.right_motor_handle = vrep.simxGetObjectHandle(clientID,
                                                                           'ePuck_rightJoint' + self.robot_number,
                                                                           vrep.simx_opmode_oneshot_wait)

    def ultrasonic_values(self):  # Calculate distances for ultrasonic Sensors
        self.det_rob = list()
        self.det_obj = list()
        for s in range(1, self.num_sensors + 1):
            self.errorCode, detectionState, detectedPoint, detectedObjectHandle, detectedSurfaceNormalVector = vrep.simxReadProximitySensor(
                self.clientID, self.sensor_handles[s - 1],
                vrep.simx_opmode_streaming + 000)  # Measure distance using Ultrasonic Sensor
            self.detectionStates[s - 1] = detectionState  # Sensor state detecting or not
            # print('detectedObjectHandle', detectedObjectHandle)
            if not detectionState:  # To overcome out of bound distance problem
                detectedPoint = [0.0] * 3
                self.det_obj_handles[s - 1] = 0
                self.sensors_detecting[s - 1] = 0
            else:  # when point is connected either it is robot aur object
                self.det_obj_handles[s - 1] = detectedObjectHandle
                if detectedObjectHandle in self.static_object_handles:  # when robot sensor detect an object
                    self.det_obj.append(detectedObjectHandle)  # handle of objects detected
                    self.sensors_detecting[s - 1] = 0
                else:  # # when robot sensor detect a robot
                    self.det_rob.append(detectedObjectHandle)  # handle of Robots detected
                    self.sensors_detecting[s - 1] = 1
            dist = np.linalg.norm(detectedPoint)  # Calculation of distance
            self.sensor_raw_values[s - 1] = dist
        self.sensor_raw_values = np.round(self.sensor_raw_values, 2)
        # print('sensor raw values', self.sensor_raw_values)
        return self.sensor_raw_values, self.detectionStates

    def sensor_mod_values(self, mindist, maxdist):  # Minimum and maximum distances b/w Robots
        for i in range(self.num_sensors):
            if mindist >= self.sensor_raw_values[i] > 0.02:
                self.sensor_values[i] = self.sensor_raw_values[i] - mindist
                self.sensor_avoid[i] = self.sensor_raw_values[i] - mindist
            elif self.sensor_raw_values[i] >= maxdist:
                self.sensor_values[i] = self.sensor_raw_values[i] - maxdist
                self.sensor_avoid[i] = 0.0
            else :
                self.sensor_values[i] = 0.0
                self.sensor_avoid[i] = 0.0
        # print('Sensor values', self.sensor_values)
        return self.sensor_values

    def object_avoidance(self, front_maxdist):  # Avoid the object in front of robot
        self.theta = 0.0
        obj_avoid_cond = (self.detectionStates[2] and (self.det_obj_handles[
                                                           2] in self.static_object_handles))  # or (self.detectionStates[6] and (self.det_obj_handles[6] in self.static_object_handles))
        # Avoid the objects along the directional Axis
        if obj_avoid_cond and (front_maxdist >= self.sensor_raw_values[
            2] > 0.01):  # or (front_maxdist >= self.sensor_raw_values[6] > 0.01)):
            print('Object avoidance behavior is active')
            fx = self.sensor_values * np.cos(self.sensor_angles)
            fy = self.sensor_values * np.sin(self.sensor_angles)
            fres_x = np.sum(fx)
            fres_y = np.sum(fy)
            self.theta = max(math.pi / 6, math.atan2(fres_y, fres_x))
            print('theta_avoid', self.theta)
        return self.theta

    def chemotaxis_gradient(self):
        all_grad = np.zeros([4])
        self.currrent_gradient = self.sensor_values[2] - self.sensor_values[6]
        max_grad = 0.0
        if (not self.detectionStates[2]) and (not self.detectionStates[6]):  # Gradient alng line of contact become Zero
            gradx = self.sensor_values[2] - self.sensor_values[6]
            grady = self.sensor_values[0] - self.sensor_values[4]
            gradxy = self.sensor_values[1] - self.sensor_values[5]
            gradyx = self.sensor_values[7] - self.sensor_values[3]
            all_grad = np.array([gradx, grady, gradxy, gradyx])
            max_grad = np.max(abs(all_grad))
            if max_grad == 0.0:  # To overcome infinite array
                all_grad = np.array([0.0] * 4)
            else:  # maximum gradient is calculated
                all_grad = all_grad / (max_grad * 8)
            # print('All Gradient', all_grad )
        return all_grad, max_grad

    def rotational_specific_angle(self, all_grad, max_grad):  # Find the angle in the direction of detected robot
        self.theta = 0.0
        random_movement = False
        #all_grad, max_grad = Robot.chemotaxis_gradient(self)
        # P = [pE, pEN, pN, pNW, pW, pWS, pS, pSE]
        P = [Robot.p + all_grad[0], Robot.p + all_grad[2], Robot.p + all_grad[1], Robot.p + all_grad[3],
             Robot.p - all_grad[0], Robot.p - all_grad[2], Robot.p - all_grad[1],
             Robot.p - all_grad[3]]  # Change probability w.r.t Gradient
            # print('Probability', P)
        if max_grad != 0.0:  # Movement in the direction of maximum gradient
            suitable_theta = np.argmax(P)  # without randomness
            # print('Robot will move Specifically at an angle of')
            random_movement = True
            self.theta = (self.thetas[suitable_theta] * math.pi / 180)
        return self.theta, random_movement

    def rotational_random_angle(self, random_rotation):
        if random_rotation:  # For Random movement of a single robot
            simulation = [random.randrange(8) * 1 for _ in range(16)]  # Randomly choose between 0-7 for 16 times
            freq = [simulation.count(i) for i in range(8)]  # Count the occuring of each number(event)
            directions = np.array([float(i * j) for i, j in zip(P, freq)])  # Possibility of each direction
            suitable_theta = np.argmax(directions)  # Select the maximum likelihood direction
            # print('Robot will move randomly at an angle of')
            self.theta = (self.thetas[suitable_theta] * math.pi / 180)

    def rotational_control_param(self):  # Convert theta to motor angular values
        if self.theta != 0:  # For both Random and Specific Rotation
            rot_time = random.uniform(1.0, 2.0)
            # v = abs(self.l * theta) / (2 * rot_time * self.r)  # t = (L * theta)/(2*v*r)
            # v = abs(0.053 * theta) / (2 * rot_time * 0.025)
            v = abs(0.053 * self.theta) / (2 * rot_time * self.r)
            if v > self.vmax:
                v = self.vmax
                rot_time = abs(0.053 * self.theta) / (2 * self.vmax * self.r)
            v_r = -v if self.theta < 0 else v
            v_l = -v_r
            # print('Robot will rotate with time {} and velocities {} and {}'.format(rot_time, v_r, v_l))
        return v_l, v_r, rot_time

    def translational_control_param(self):  # Convert theta to motor speed
        if self.theta != 0:  # For both Random and Specific Rotation
            if self.currrent_gradient > 0.0 and (not self.det_obj_handles[2] in self.static_object_handles):  # Move straight
                v_l = self.currrent_gradient * 30
                v_r = self.currrent_gradient * 30
                rot_time = 1
                # print('Robot will move straight with time {} and velocities {} and {}'.format(rot_time, v_r, v_l))
            elif self.currrent_gradient < 0.0 and (not self.det_obj_handles[6] in self.static_object_handles):  # Move backword
                v_l = self.currrent_gradient * 30
                v_r = self.currrent_gradient * 30
                rot_time = 1
                # print('Robot will move backword with time {} and velocities {} and {}'.format(rot_time, v_r, v_l))
            #elif self.currrent_gradient == 0.0 and self.det_rob:  # not all(v == False for v in self.det_rob):  # Move backword
                #v_l = self.currrent_gradient * 30
                #v_r = self.currrent_gradient * 30
                #rot_time = 1
            else: # self.r_rot:  #  Move Randomly straight
                v_l = 2.5
                v_r = 2.5
                rot_time = random.uniform(3.0, 4.0)
                self.r_rot = True  # To Randomly rotate in next step
        return v_l, v_r, rot_time

    def random_straight(self, direction):
        v_l = direction * 2.5
        v_r = direction * 2.5
        rot_time = random.uniform(4.0, 5.0)
        return v_l, v_r, rot_time

    def neighbor_check(self):
        nei_status = False
        self.no_nei = self.detectionStates.count(True)
        if self.no_nei > 1:
            nei_status = True
        return nei_status

    def movement(self, v_left, v_right):
        self.errorCode = vrep.simxSetJointTargetVelocity(self.clientID, self.left_motor_handle, v_left,
                                                         vrep.simx_opmode_oneshot)

        self.errorCode = vrep.simxSetJointTargetVelocity(self.clientID, self.right_motor_handle, v_right,
                                                         vrep.simx_opmode_oneshot)

    def wait(self, t):
        # print('time of wait is', t)

        self.errorCode = vrep.simxSetJointTargetVelocity(self.clientID, self.left_motor_handle, 0.0,
                                                         vrep.simx_opmode_oneshot)
        self.errorCode = vrep.simxSetJointTargetVelocity(self.clientID, self.right_motor_handle, 0.0,
                                                         vrep.simx_opmode_oneshot)
        time.sleep(t)'''